# Exercice Kubernetes 2 
## D√©ploiement progressif d'une application (Peppermint) avec une base de donn√©es (Posgtres)

---

## Objectifs p√©dagogiques

√Ä la fin de cet exercice, l‚Äôapprenti sera capable de :

- Comprendre la diff√©rence entre **Pod** et **Deployment**
- Comprendre pourquoi une **base de donn√©es a besoin de persistance**
- Mettre en √©vidence la perte de donn√©es **sans volume**
- Utiliser un **PersistentVolumeClaim (PVC)**
- Comprendre l‚Äôutilit√© des **Secrets**
- Utiliser les **Services** pour la communication interne
- D√©ployer une application compl√®te (**Peppermint + PostgreSQL**)
- Exposer une application via un **Ingress NGINX**

> üí° Cet exercice est volontairement progressif.  
> Certaines √©tapes sont **incorrectes d‚Äôun point de vue production**, mais **essentielles pour comprendre**.

---

## Pr√©requis

- Acc√®s √† un cluster Kubernetes fonctionnel
- `kubectl` configur√©
- Un **Ingress Controller NGINX** d√©j√† pr√©sent sur le cluster
- Connaissances de base en Docker et YAML

---

## √âtape 0 ‚Äî Pr√©paration de l‚Äôenvironnement

### Objectif
Isoler le travail dans un namespace d√©di√©.

### Commandes
```bash
#Ici on part du principe que vous avez un namespace √† vous
kubectl config set-context --current --namespace=<mon-namespace>
#la commande ci-dessus permet de d√©finir votre namespace pour namespace courant. Ce qui signifie que par d√©faut les ressources cr√©√©es, le seront dans votre namespace par d√©faut si aucun namespace n'est pr√©cis√©s.
```

### R√©sultat attendu
- Le namespace `peppermint` existe
- Toutes les ressources cr√©√©es ensuite seront dans ce namespace

---

## √âtape 1 ‚Äî D√©ployer PostgreSQL sans volume (cas volontairement faux)

### Objectif p√©dagogique
Comprendre que **sans volume**, une base de donn√©es **perd ses donn√©es** lorsque le Pod est recr√©√©.

### D√©ploiement PostgreSQL (sans PVC, sans Secret)

Cr√©er le fichier `01-postgres-no-volume.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: peppermint-postgres # Nom du Deployment (r√©f√©rence Kubernetes)
spec:
  replicas: 1 # Pour une base de donn√©es, on garde 1 seul replica
  selector:
    matchLabels:
      app: peppermint-postgres # Doit correspondre aux labels du template
  template:
    metadata:
      labels:
        app: peppermint-postgres # Labels appliqu√©s aux Pods cr√©√©s par ce Deployment
    spec:
      containers:
        - name: postgres
          image: postgres:18 # Image officielle Postgres (ici latest pour l'exercice)
          ports:
            - containerPort: 5432 # Port expos√© par le conteneur PostgreSQL
          env:
            - name: POSTGRES_USER
              value: peppermint # Utilisateur PostgreSQL en clair ‚Äî NE PAS faire en production
            - name: POSTGRES_PASSWORD
              value: "1234" # Mot de passe en clair ‚Äî NE PAS faire en production
            - name: POSTGRES_DB
              value: peppermint # nom de la db initiale
```

### Appliquer
```bash
kubectl apply -f 01-postgres-no-volume.yaml
kubectl get pods
```

### R√©sultat attendu
- Un Pod PostgreSQL en √©tat `Running`

---

## √âtape 2 ‚Äî Tester la base de donn√©es et constater la perte de donn√©es

### Objectif
Cr√©er des donn√©es **√† la main**, puis observer leur disparition.

### Connexion au conteneur PostgreSQL
```bash
kubectl get pods
kubectl exec -it <nom-du-pod> -- psql -U peppermint -d peppermint 
#Cette commande √©xecute la commande "psql -U peppermnint -d peppermint" $ l'int√©rieur du conteneur.
#Il est aussi possible de faire un "port-forward" et de vous y connecter via un client postgres local.
```

### Dans PostgreSQL
```sql
CREATE TABLE demo (id serial PRIMARY KEY, message text);
INSERT INTO demo(message) VALUES ('hello kubernetes');
SELECT * FROM demo;
```

### R√©sultat attendu
- La table existe
- Une ligne est pr√©sente

### Supprimer le Pod
```bash
kubectl delete pod <nom-du-pod>
kubectl get pods
```

Reconnectez-vous √† PostgreSQL et testez :
```sql
SELECT * FROM demo;
```

### R√©sultat attendu
- Erreur ou table inexistante  
- **Les donn√©es ont disparu**

**Conclusion interm√©diaire**  
- Un Pod peut √™tre recr√©√© √† tout moment.  
- Une base de donn√©es **ne doit jamais d√©pendre uniquement du Pod pour ces donn√©es**.

---

## √âtape 3 ‚Äî Ajouter la persistance avec un PersistentVolumeClaim (PVC)

### Objectif 
S√©parer :
- le **calcul** (Pod)
- le **stockage** (Volume)

### Cr√©er le PVC


 Description :
 Un PVC est une demande de stockage persistant effectu√©e par un utilisateur ou un Pod dans Kubernetes.
 Il d√©crit la quantit√© de stockage, le(s) mode(s) d'acc√®s et la classe de stockage souhait√©e, sans
 exposer les d√©tails du support physique sous-jacent.



Fichier `02-postgres-pvc.yaml` :


```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-data # Nom du PVC utilis√© par le Deployment
spec:
  accessModes:
    - ReadWriteOnce # Acc√®s en lecture/√©criture par un seul n≈ìud (adapt√© √† Postgres)
  resources:
    requests:
      storage: 5Gi # Taille demand√©e pour le volume persistant
  storageClassName: exoscale-sbs # type de stockage du cluster k8s, exoscale-sbs par d√©faut sur SKS
```


```bash
kubectl apply -f 02-postgres-pvc.yaml
kubectl get pvc
```

### R√©sultat attendu
- PVC en √©tat `Bound`

---

## √âtape 4 ‚Äî PostgreSQL avec volume persistant

### Objectif
Monter le volume sur `/var/lib/postgresql/data`. C'est le r√©pertoire des data du conteneur postgres.

Fichier `03-postgres-with-volume.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: peppermint-postgres # Nom du Deployment
spec:
  replicas: 1 # Nombre de r√©plicas (pour une DB, toujours 1 dans un deployment)
  selector:
    matchLabels:
      app: peppermint-postgres # S√©lecteur pour lier le ReplicaSet / Pods
  template:
    metadata:
      labels:
        app: peppermint-postgres # Labels appliqu√©s aux Pods cr√©√©s
    spec:
      containers:
        - name: postgres
          image: postgres:18 # Image officielle Postgres
          ports:
            - containerPort: 5432 # Port expos√© dans le conteneur
          env:
            - name: POSTGRES_USER
              value: peppermint # Utilisateur PostgreSQL (sera remplac√© par un Secret plus tard)
            - name: POSTGRES_PASSWORD
              value: "1234" # Mot de passe en clair (√† s√©curiser via Secret)
            - name: POSTGRES_DB
              value: peppermint # Base de donn√©es initiale
          volumeMounts:
            - name: postgres-data #nom du volume √† monter, d√©clar√© plus bas.
              mountPath: /var/lib/postgresql # R√©pertoire des donn√©es PostgreSQL
      volumes:
        - name: postgres-data
          persistentVolumeClaim:
            claimName: postgres-data # Lie le PVC (02-postgres-pvc.yaml) au Pod
```

```bash
kubectl apply -f 03-postgres-with-volume.yaml
kubectl rollout status deploy/peppermint-postgres
```

### Test de persistance
- Recr√©ez la table `demo`
- Supprimez le Pod
- V√©rifiez que les donn√©es sont **toujours pr√©sentes**

### R√©sultat attendu
  Les donn√©es persistent

---

## √âtape 5 ‚Äî S√©curiser la configuration avec un Secret

### Objectif p√©dagogique
Ne plus stocker de mots de passe en clair dans les manifests.

Fichier `04-postgres-secret.yaml` :

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
type: Opaque
stringData:
  POSTGRES_USER: peppermint     # Nom d'utilisateur PostgreSQL utilis√© par l'application
  POSTGRES_PASSWORD: "1234"     # Mot de passe en clair (exercice). En prod, utilisez un secret fort.
  POSTGRES_DB: peppermint       # Nom de la base de donn√©es initiale
# Utilisation :
# Dans le Deployment, remplacer les variables d'env par :
# envFrom:
#   - secretRef:
#       name: postgres-secret
```

```bash
kubectl apply -f 04-postgres-secret.yaml
kubectl get secrets
kubectl get secret postgres-secret -o yaml 
```
Vous devriez voir que vos **secrets** sont encod√©s en base 64


### Mise √† jour du Deployment
Dans  `03-postgres-with-volume.yaml`, 
remplacer `env:` par :

```yaml
envFrom:
  - secretRef:
      name: postgres-secret
```
```bash
kubectl apply -f 03-postgres-with-volume.yaml
```
### R√©sultat attendu
- PostgreSQL fonctionne toujours
- Les credentials ne sont plus visibles dans le YAML

---

## √âtape 6 ‚Äî Exposer PostgreSQL avec un Service

### Objectif
Permettre √† une application de se connecter via un **nom DNS stable**.

Cr√©er un fichier `05-postgres-service.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: peppermint-postgres # Nom du Service pour PostgreSQL (DNS: peppermint-postgres)
spec:
  selector:
    app: peppermint-postgres # Lie le Service aux Pods du Deployment postgres
  ports:
    - name: postgres # Nom logique du port (utile pour la lisibilit√©)
      port: 5432 # Port expos√© par le Service √† l'int√©rieur du cluster
      targetPort: 5432 # Port sur lequel le conteneur PostgreSQL √©coute
      protocol: TCP # Protocole utilis√© (TCP par d√©faut pour Postgres)
  type: ClusterIP # Service interne au cluster (valeur par d√©faut)
```
Le Service fournit une IP interne stable et un nom DNS : dans le m√™me namespace, PostgreSQL reste joignable via `peppermint-postgres`, alors qu‚Äôun Pod peut voir son IP changer √† chaque red√©marrage ou crash.

Le champ `selector` associe le Service aux Pod(s) cibl√©s via des labels. Ici, le label `app: peppermint-postgres` d√©fini dans le Deployment permet au Service de retrouver et router le trafic vers les Pods PostgreSQL.
```bash
kubectl apply -f 05-postgres-service.yaml
kubectl get svc
```

Ici vous pouvez √©ventuellement faire un test de connexion avec un client posgres et un port-fowrard
```bash
kubectl port-forward svc/peppermint-postgres 5432:5432
# puis, depuis la machine locale, sur un autre terminal :
psql "host=localhost port=5432 user=peppermint dbname=peppermint"
```

### R√©sultat attendu
- Service `peppermint-postgres`
- Accessible uniquement √† l‚Äôint√©rieur du cluster

---

## √âtape 7 ‚Äî D√©ployer l‚Äôapplication Peppermint

### Objectif
D√©ployer une application r√©elle (Peppermint) utilisant PostgreSQL. Peppermint r√©cup√®re ses identifiants de connexion via des variables d‚Äôenvironnement : nous allons donc cr√©er un Secret pour stocker ces credentials, comme pour PostgreSQL pr√©c√©demment.

Peppermint fournit une documentation pour un d√©ploiement via docker-compose.
Nous nous en inspirons pour le faire via kubernetes, https://docs.peppermint.sh/docker 

### Secret Peppermint

Fichier `06-peppermint-secret.yaml` :

```yaml

apiVersion: v1
kind: Secret
metadata:
    name: peppermint-secret
type: Opaque
stringData:
    DB_USERNAME: peppermint       # Nom d'utilisateur PostgreSQL
    DB_PASSWORD: "1234"           # Mot de passe (exercice). En prod, utilisez un secret fort.
    DB_HOST: peppermint-postgres  # Service DNS interne pointant vers PostgreSQL
    SECRET: peppermint4life       # Secret applicatif (utilis√© par Peppermint)
```

```bash
kubectl apply -f 06-peppermint-secret.yaml
```

### Deployment Peppermint

Fichier `07-peppermint-deployment.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: peppermint
spec:
  replicas: 1
  selector:
    matchLabels:
      app: peppermint
  template:
    metadata:
      labels:
        app: peppermint
    spec:
      containers:
        - name: peppermint
          image: pepperlabs/peppermint:latest
          env:
          - name: HOSTNAME
            value: "0.0.0.0"
          ports:
            - containerPort: 3000
            - containerPort: 5003
          envFrom:
            - secretRef:
                name: peppermint-secret
```

```bash
kubectl apply -f 07-peppermint-deployment.yaml
kubectl logs -l app=peppermint -f #Elle affiche en continu les logs des conteneurs dont les Pods ont le label : app=peppermint
```

### R√©sultat attendu
- Pod Peppermint en `Running`
- Logs sans erreur de connexion DB

---

## √âtape 8 ‚Äî Service Peppermint + test local
De la m√™me mani√®re que pour la DB, on cr√©er un service affin d'avoir un point d'entr√©e stable avec un nom DNS interne.
A noter que peppermint √©coute sur 2 ports. 3000 pour le partie front.
Fichier `08-peppermint-service.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: peppermint
spec:
  selector:
    app: peppermint
  ports:
    - name: web
      port: 3000
      targetPort: 3000

```

```bash
kubectl apply -f 08-peppermint-service.yaml
kubectl port-forward svc/peppermint 3000:3000
```

‚û°Ô∏è Acc√®s : http://localhost:3000
- user: admin@admin.com
- password: 1234

---

## √âtape 9 ‚Äî Exposition publique avec Ingress

### Objectif
Rendre l‚Äôapplication accessible depuis Internet.

Fichier `09-peppermint-ingress.yaml` :

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: peppermint
  # annotations: # √©ventuelles annotations pour TLS, redirections, etc.
spec:
  ingressClassName: nginx # classe d'Ingress g√©r√©e par l'Ingress Controller NGINX
  rules:
    - host: peppermint.X.X.X.X.nip.io # nom DNS public (nip.io r√©sout l'IP encod√©e dans le nom), demander l'ip publique du controller ingress √† votre enseignant si inconnu.
      http:
        paths:
          - path: /
            pathType: Prefix # route toutes les requ√™tes dont le chemin commence par "/"
            backend:
              service:
                name: peppermint # Service Kubernetes cible (d√©fini en 08-peppermint-service.yaml)
                port:
                  number: 3000 # port expos√© par le Service pour la partie front
```

```bash
kubectl apply -f 09-peppermint-ingress.yaml
kubectl get ingress
```

### R√©sultat attendu
- Acc√®s via navigateur public http://peppermint.X.X.X.X.nip.io
- Application fonctionnelle

---

## Nettoyage

```bash
Supprimer toutes les resources cr√©√©es dans cet exercice
kubectl get all -n my-ns #affiche toues les resources du namespace

```
<span style="color:red">ATTENTION</span>
```bash
kubectl delete -f . #supprimes les ressource correspondantes aux fichiers yaml du r√©pertoire courant
```
---

## Bilan

‚úî Compr√©hension du cycle de vie d‚Äôun Pod  
‚úî Importance des volumes pour les bases de donn√©es  
‚úî S√©paration configuration / secrets  
‚úî Communication interne via Services  
‚úî Exposition externe via Ingress  
‚úî D√©ploiement d‚Äôune application compl√®te sur Kubernetes
